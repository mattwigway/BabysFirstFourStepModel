---
title: "My First Four-Step Model: a Simple and Accessible Tool to Teach Travel Demand Modeling"
author:
  - name: Matthew Wigginton Bhagat-Conway
    affiliations:
      - name: University of North Carolina at Chapel Hill
        department: Department of City and Regional Planning
        address: "223 E Cameron Ave, CB #3140"
        city: Chapel Hill
        state: NC
        country: USA
        postal-code: 27599
    orcid: 0000-0002-1210-2982
    email: mwbc@unc.edu
abstract: |
  We traditionally teach travel demand modeling focusing primarily on theory. Introductory courses cover the basic design of a four-step or activity-based model, while more advanced courses dive into statistical theory, discrete-choice models, and so on. Few students ever work with an actual travel demand model. In this article, I describe a new technique I use for teaching demand modeling in my introductory Planning Methods class. Students run a very simplified travel demand model early on, interpreting the process and the outputs and understanding how a model is used. Some students go on to take more advanced modeling classes that cover the relevant theory, and some do not, but all have experience with the general structure and use of a model. To support this, I introduce a new R package, My First Four-Step Model, that implements the simple model. This article provides step-by-step instructions to set up and use this model.

  Providing all students hands-on experience with a travel demand model helps promote better understanding of the practice of demand modeling. While most of my students will not go on to be modelers, many will consume travel demand model output at some point during their careers. Having this hands-on experience with a model will help promote better communication with modelers, an understanding of the uncertainy inherent in model results, and an ability to identify new uses for existing travel demand models.
keywords: [travel demand modeling, teaching, education, open-source]
bibliography: bibliography.bib
format: trb-pdf
date: 2024-07-31
ntables: 3
execute:
    eval: true
    echo: true
    output: true
    cache: true
fig-dpi: 300
---

```{r}
#| include: false
library(tidyverse)
library(gridExtra)
library(gt)
```

# Introduction

The four-step travel demand model is ubiquitous in transportation planning. It was one of the earliest travel demand models developed [@weiner_urban_2013;@federalhighwayadministration_planpac_1977]. While it has come under significant criticism lately [@mladenovic_shortcomings_2014], it remains in common use. Many large regions have transitioned to more modern activity-based models, but many smaller regions and even some large ones continue to use the four-step model.

Most transportation programs in  planning and engineering cover travel demand modeling to some extent [@zhou_transportation_2009]. In my experience, it is almost invariably taught with a "bottom-up" approach. Students take classes on transportation planning, econometrics, and choice modeling. Students then work with individual components of demand models, such as a trip generation or mode choice model. Often, students never "put it all together" to run a regional model from start to finish. The vast majority of learning time is spent on theory and mathematics, rather than applications.

Theory and mathematics are paramount for those who will build and run travel demand models themselves. This is a very small group of students, however, especially in planning. At most metropolitan planning organizations and DOT's, demand models are estimated and run either by consultants or a small in-house team. However, consumers of model output are a  larger group: transportation planners, land use planners, developers, advocates, and so on. For this larger group, only a cursory understanding of the mathematics is required;  the general mechanisms and assumptions the model relies on are far more important.

A better understanding of modeling among this group will help promote better communications between modelers and model consumers. Consumers will be more aware of what the model can and can't do, and more able to come up with situations where the model may be helpful. Understanding will also promote a "healthy skepticism" of the model, enabling feedback from users on the model and ultimately leading to better models and decision support.

In this article, I introduce a "top-down" approach to teaching modeling. In this approach, the first step is a very high-level discussion of the steps in the four-step model, followed immediately by students actually running a complete (albeit simplified) four-step model, and interpreting the output. Students interested in modeling may take further classes, but all students will have some first-hand experience with demand models---something many students do net get at all today, even after taking many classes on modeling.  I use this approach in my Introduction to Planning Methods course, where we spend only a week discussing transportation modeling and engineering, and at the conclusion the students run a simple demand model and future scenario for the Research Triangle region of North Carolina. 

To facilitate teaching in this way, I introduce the "My First Four-Step Model" R package, a very simple four-step model that can run quickly on typical consumer-grade computers without complex software dependency installation processes or expensive licensing. It can be estimated for any US metropolitan area using only publicly-available data. The goal of the package is to enable a much broader swath of planners and engineers to work with a travel demand model during their education.  The model is highly simplified, and this certainly affects its predictive accuracy, but predictive accuracy is not the point. Epstein [-@epstein_why_2008] lists 16 reasons to build models other than prediction; one of them, train practitioners, is the primary goal of this model. This goal does not depend on high predictive accuracy.
This article discusses the model structure and implementation and how I use it in the classroom, and includes R code to estimate and run a complete four-step model for anywhere in the US.

# Literature review

There is little literature on pedagogical practices surrounding travel demand modeling. Most transportation planning and engineering programs cover the topic [@zhou_transportation_2009], but it was not even included on a semi-regular survey of transportation faculty regarding what they consider the most important topics in introductory courses [@turochy_structuring_2013].

There is, however, a long history of pedagogy around teaching through simulating real-world activities undertaken by practitioners, rather than through one-to-many classroom instruction. This is most well established in the medical field, with positive outcomes for student learning [@mcgaghie_critical_2010]. Simulation activities are widely used in transportation engineering instruction [@hurwitz_transportation_2015], and research on active learning techniques in transportation engineering goes back decades [@weir_active_2004]. Simulation activities in planning have a similarly long history [e.g., @meier_gaming_1966].

Effective simulations as an educational tool often take the form of a game. Solving transportation challenges is one of the recurrent examples in the foundational book on gamification in education, Clark Abt's _Serious Games_ [@abt_serious_1970]. More recently, physical board games have been used to teach transportation planning using both popular-press games [@huang_game_2012] and purpose-built educational games [@paget-seekins_transform_2021].

Computer-based simulations have rapidly become ubiquitous in transportation engineering education [@hurwitz_transportation_2015]. Liao, Liu, and Levinson [-@liao_simulating_2009] built a web-based traffic simulation tool to help students experiment with signal timing practices. The interactive A/B Street traffic-simulation software has likewise been used in undergraduate courses at Arizona State University [@carlino_street_2024]. An economic simulation of airline operations has also been applied to help budding engineers understand airline operations [@luken_case_2011].

Computer-based simulations have also been applied in planning, although perhaps less frequently. Simulations in planning classrooms often take the form of commercial planning games, such as SimCity or Cities: Skylines [@gaber_simulating_2007;@khan_perceptions_2021], likely due to less funding for purpose-built simulations in planning as opposed to engineering. A significant challenge with commercial games is that they are intended primarily for entertainment, and thus may oversimplify or even modify system dynamics to support enjoyable gameplay rather than educational outcomes [@gaber_simulating_2007;@walker_did_2009]. The advantage is that commercial games are more likely to receive significant upfront investment as well as continued support, a significant problem with games developed for educational purposes [@sobke_two_2018].

Public education and communication are another arena of planning where gamification and simulation have been deployed. The _Future Energy Chicago_ exhibit at Chicago's Museum of Science and Industry engages participants in a several-hour, facilitated game to improve energy outcomes. Survey data suggests that the game improved some aspects of willingness to conserve energy [@applebaum_collaboration_2021]. The CityScope platform provides a hands-on physical environment wherein members of the public can make land-use changes to a Lego model of a neighborhood and see computer simulation output regarding transport and energy consumption in real time [@alonso_cityscope_2018]. The CoAXs platform allows meeting participants to see how proposed Bus Rapid Transit routes would affect their ability and the ability of other citizens to reach key destinations, and was found to support improved learning and discussion outcomes among participants [@stewart_coaxs_2016;@stewart_mapping_2017]. All of these simulations are perforce somewhat simpler than might be used in a classroom environment, since they target the general public rather than future practitioners.

Teaching travel demand modeling differs from other places where simulations have been deployed in transportation education. Travel demand models are themselves simulations of complex urban systems. Applying them in a classroom environment does not demand developing a new simulation. Rather, it means simplifying the existing structure of demand models to create one suitable for students with only a rudimentary understanding of the theory and mathematics involved.

The only travel demand modeling software designed specifically for education I am aware of is the now-defunct ADAM project [@zhu_enhancing_2011], which implemented a simple agent-based model for transportation education. This model was primarily a network assignment model for simple networks; it started with production (workers) and attractions (jobs), and the task was to modify the network to reduce congestion. The software included a simple network editor, and was deployed as a Java applet which at the time was widely accessible (though Java applets are now obsolete). Likely due to computational limits in place at the time, it worked with a very simple network of only 24 nodes and 68 links.

# My first four-step model

My First Four-Step Model is a software package designed to allow students with minimal experience and consumer-grade computer hardware to run a simple four-step travel demand model. It is implemented as an R package [@r_2024], which has several advantages. R is a free, open-source, and cross-platform statistical programming language, allowing students to run it on their own computers regardless of configuration. Furthermore, R is becoming the _lingua franca_ of quantitative urban planning. Using the My First Four-Step Model package in an assignment gives students a gentle introduction to the language and potentially piques their interest in learning more. The package has several key design goals:

\quad

1. The four steps of the model should map directly onto four functions in the package;
1. Simplicity is paramount—any place where there is a tradeoff between simplicity and predictive accuracy, simplicity is chosen;
1. It should be able to be estimated for any location in the United States using only publicly-available data;
1. There should be intuitive tools to visualize model inputs, outputs, and parameters, so students can interpret them and understand how the model works;
1. Preparing land-use and transportation scenarios should be simple;
1. It should run on any computer a student is likely to have—Windows, Mac, Linux, or Chromebook, old or new, cheap or expensive; and
1. It should depend only on R itself and common R packages that are easily installed on all platforms from the Comprehensive R Archive Network (CRAN).

\quad

The open-source (MIT licensed) package is available on Github at\
[https://github.com/mattwigway/MyFirstFourStepModel](https://github.com/mattwigway/MyFirstFourStepModel). In the sections below, I discuss how I implement the model in the classroom environment (including complete code to run the model), then turn to the estimation processes and technical details of the model.

# Implementation in the classroom

I use the package in my Planning Methods course in the Department of City and Regional Planning at the University of North Carolina at Chapel Hill. This is an introductory master's level course which all planning students (not only those in transportation) take, generally during their first semester. In the course, I spend only a week discussing transportation planning and engineering. Other topics covered include statistics, qualitative research, survey development, demographic forecasting, development finance, and so on. I give a single hour-and-fifteen-minute lecture on transportation modeling, covering primarily the four-step model, but with a nod to activity-based models as well. I then have an assignment where all students run and interpret the output of a four-step model, which I describe in more detail momentarily. The goal is to enable planners in all specializations to understand basic demand model structure, and have productive conversations with modelers. Our department also teaches a semester-long travel demand modeling course using a more complex model developed in TransCAD, which most transportation specialization students take later in their program.

I provide the students with an R file, all of the code of which is included inline in this section,^[I have only taught this class once so far, and the code provided is slightly different from what was originally provided to students to account for changes to the package since the course was taught.] to run the model, and visualize the results. For each step of the model, I have 1–2 homework questions about interpreting the model and its output.

## Installation

All my students already have R and RStudio installed on their machines from a previous exercise on linear regression. Installing My First Four-Step Model is simple; students run the following R code at the command prompt to install the package:

```{r}
#| eval: false
install.packages("devtools")
devtools::install_github("mattwigway/MyFirstFourStepModel")
```

This installs the `devtools` package [@devtools_2022], which is used to install `MyFirstFourStepModel` directly from Github. It also automatically installs the R packages `MyFirstFourStepModel` depends on—notably `tidyverse` [@tidyverse], `sf` [@sf], `igraph` [@igraph], `readxl` and `writexl` [@readxl;@writexl], `tidycensus` [@tidycensus], `tigris` [@tigris], and `nnet` [@nnet].

## Loading the package and the model

Next, students load the `MyFirstFourStepModel` package, and an already-estimated model. Most model users will never estimate a full demand model themselves, so I provide an already-estimated model for the Research Triangle region of North Carolina. Instructions for model estimation in other regions are discussed below. The already-estimated model can be read either from a local file or directly from an `https` URL. Reading directly from a URL requires the instructor to have access to a server, but avoids needing to troubleshoot local file paths. The URL included below is a live URL with the reference model for the Research Triangle.

```{r}
library(MyFirstFourStepModel)
model = load_model("https://files.indicatrix.org/rdu.model")
```

## Trip generation

The first step of the four-step process is trip generation, which estimates production and attraction. Trip generation is done at the household level using linear regression. I use linear regression rather than traditional cross-classification or more complex regression methods because of its ease of interpretation, and because I teach my basic unit on demand modeling shortly after teaching regression. Before running the trip generation model, I have have students view the trip generation model for AM Peak home-based work trips, using the code below, and interpret the coefficients (@tbl-production).

```{r}
#| eval: false
summary(model$production_functions$`AM Peak`$HBW)
```

```{r}
#| echo: false
#| label: tbl-production
#| tbl-cap: Trip production regression for AM Peak home-based work trips
summary(model$production_functions$`AM Peak`$HBW)$coefficients %>%
    as_tibble(rownames="Coefficient") %>%
    mutate(Coefficient=case_match(Coefficient,
      "vehicles" ~ "Number of vehicles",
      "hhsize" ~ "Household size",
      "factor(income) 35000" ~ "Income 35,000-74,999",
      "factor(income) 75000" ~ "Income 75,000-99,999",
      "factor(income)100000" ~ "Income > 100,000",
      "HTRESDN" ~ "Housing unit density in home tract (units/square mile)",
      "workers" ~ "Number of workers",
      .default=Coefficient
    )) %>%
    gt() %>%
        fmt_number()
```

I similarly have them interpret one of the regressions for attraction functions (coefficients not shown for brevity):

```{r}
#| eval: false
summary(model$attraction_functions$`AM Peak`$HBW)
```

Once students have interpreted the regressions, I have them run the trip generation step. True to the design goals, this requires only a single function.

```{r}
productions_attractions = trip_generation(model, model$scenarios$baseline)
```

Students can then map the number of trips produced and attracted in each Census tract in the region using the `map_trip_generation` function as shown below, and describe the spatial pattern ([@fig-generation]).

```{r}
#| eval: false
map_trip_generation(
  model,
  productions_attractions,
  "Productions",
  "AM Peak",
  "HBW"
)

map_trip_generation(
  model,
  productions_attractions,
  "Attractions",
  "AM Peak",
  "HBW"
)
```

```{r}
#| label: fig-generation
#| fig-cap: Home-based work trip productions and attractions for the Research Triangle region, AM Peak
#| fig-alt: AM Peak home-based work trip productions and attractions. Productions are spread across the region, whereas attractions are more concentrated.
#| echo: false
grid.arrange(
    map_trip_generation(model, productions_attractions, "Productions", "AM Peak", "HBW") +
        theme(legend.position="bottom", legend.text=element_text(angle=-45, hjust=0)),
    map_trip_generation(model, productions_attractions, "Attractions", "AM Peak", "HBW") +
        theme(legend.position="bottom", legend.text=element_text(angle=-45, hjust=0)),
    nrow=1,
    ncol=2
)
```

## Trip distribution

Trip distribution uses a simple gravity model, with different parameters estimated for home-based work, home-based other, and non-home-based trips. I first have students print the parameters using the code below, and interpret them (the estimated values for the Research Triangle region are -1.21 for home-based work trips, -1.87 for home-based other trips, and -1.71 for non-home-based trips).

```{r}
#| eval: false
model$distribution_betas
```

Then, they can run the trip distribution step with the following code

```{r}
flows = trip_distribution(
  model,
  model$scenarios$baseline,
  productions_attractions
)
```

Students can then map the trip distribution results for any origin Census tracts, and interpret them. @fig-distribution shows the results for AM Peak home-based work trips originating from a tract in suburban Durham; results show that many trips stay local, but there are also pockets of activity in further-flung large employment centers (e.g., Raleigh).

\newpage

```{r}
#| label: fig-distribution
#| fig-alt: AM Peak trip distribution from a census tract in suburban Durham, NC; most trips go to nearby destinations, but some go to further-flung large employment centers near Raleigh
#| fig-cap: AM Peak trip distribution, from a selected tract in suburban Durham, NC
map_trip_distribution(
  model,
  flows,
  "AM Peak",
  "HBW",
  origin_tract="37063002025"
)

```

## Mode choice

The mode choice model is a multinomial logit model with four modes: walk, bike, transit, and drive. Since the model is estimated from public data, there are minimal attributes of each individual trip available for estimation, so the model is very simple and primarily based on Euclidean distance between the origin and destination. I give a very basic expanation of the multinomial logit model, highlighting  commonalities with linear regression, and have students print the mode choice model using the code below, and interpret a few coefficients  (@tbl-mc):

```{r}
#| eval: false
summary(model$mode_choice_models$HB)
```

\footnotesize
```{r}
#| echo: false
#| label: tbl-mc
#| tbl-cap: Coefficients from the multinomial logit mode choice model, for home-based trips
s = summary(model$mode_choice_models$HB)
cf = format(round(s$coefficients, 4), scientific=F)

colnames(cf) =  str_replace(colnames(cf), "factor\\(.*\\)", "")

t = s$coefficients / s$standard.errors
cf[abs(t) > 1.96] = paste0(cf[abs(t) > 1.96], "*")
cf[abs(t) <= 1.96] = paste0(cf[abs(t) <= 1.96], " ")

cf[abs(t) > 2.58] = paste0(cf[abs(t) > 2.58], "*")
cf[abs(t) <= 2.58] = paste0(cf[abs(t) <= 2.58], " ")

cf[abs(t) > 3.29] = paste0(cf[abs(t) > 3.29], "*")
cf[abs(t) <= 3.29] = paste0(cf[abs(t) <= 3.29], " ")

cf %>%
    as_tibble(rownames="Mode") %>%
    gt() %>%
    cols_label(
      HTRESDN="Density",
      dist_km="Trip length (km)",
      HBW="Work trip"
    ) %>%
    tab_source_note("* = p < 0.05, ** = p<0.01, ***=p < 0.001") %>%
    tab_footnote("Homes/sq. mi. in home Census tract", cells_column_labels(3)) %>%
    tab_options(table.font.size=10)
```

\normalsize

I then have students run the mode choice step and calculate mode shares, using the code below; for the Triangle region, they are 91% car, 5% walk, 3% transit, and 1% bike in the baseline case.

```{r}
#| output: false
flows_by_mode = mode_choice(model, model$scenarios$baseline, flows)
get_mode_shares(flows_by_mode)
```


## Network assignment

The final step of the model is network assignment. Road networks for anywhere in the US are extracted from OpenStreetMap, and a simple Frank-Wolfe static traffic assignment algorithm is used to assign trips to the network. The algorithm is written in pure R for ease of installation, at the expense of some performance; for this reason a relatively simple network is used. The network used in the Research Triangle example model has 6969 nodes and 9814 edges. Assignment is done for a single time period, and students then map and interpret congestion patterns (@fig-congestion). The code below performs assignment for the PM Peak and displays congestion results.

```{r}
#| eval: false
pm_network_flows = network_assignment(
  model,
  model$scenarios$baseline,
  flows_by_mode,
  "PM Peak"
)
map_congestion(model, pm_network_flows)
```

```{r}
#| echo: false
#| output: false
pm_network_flows = network_assignment(model, model$scenarios$baseline, flows_by_mode, "PM Peak")
```

```{r}
#| echo: false
#| label: fig-congestion
#| fig-cap: Forecast PM Peak congestion
#| fig-alt: Map of forecast PM Peak congestion, with heavy congestion on some major routes and light congestion elsewhere.
map_congestion(model, pm_network_flows)
```

Congestion is not the only useful metric produced by travel demand models. To address environmental concerns, agencies are increasingly interested in total vehicle miles traveled. The assignment step can also estimate VMT by period using the code below. For the PM Peak in the Research Triangle, this is estimated to be 6 million miles/day. The 2017 Local Area Transportation Characteristics for Households (LATCH) statistics estimate total VMT in the Triangle region to be 25 million miles/day [author calculations from @bureauoftransportationstatistics_2017_2024], so 6 million in the PM Peak seems reasonable.

```{r}
estimate_vmt(model, pm_network_flows, "PM Peak")
```

## Land-use scenarios

The code above runs a complete, if simplified, four-step model for baseline conditions. However, we are generally more interested in forecasts for future years under different scenarios. In the code above, I specified using the baseline in a few places by specifying `model$scenario$baseline`. The baseline is automatically created during model estimation based on Census population and employment data. Additional scenarios can be created using a simple Excel format, shown in @tbl-demographic-scenario, specifying the number of households in different household size, income, vehicle ownership, and number of worker categories. 

|  `geoid`      | `marginal` | `value` | `count` |
|:------------|:-------|--:|---:|
| 37183053411 | `hhsize` | 1 | 514 |
| 37183053411 | `hhsize` | 2 | 711 |
| 37183053411 | `hhsize` | 3 | 940 |
| 37183053411 | `hhsize` | 4 | 1907 |
| 37183053411 | `income` | 0 | 358 |
| 37183053411 | `income` | 35000 | 595 |
| 37183053411 | `income` | 75000 | 183 |
| 37183053411 | `income` | 100000 | 2936 |
| 37183053411 | `vehicles` | 0 | 110 |
| 37183053411 | `vehicles` | 1 | 921 |
| 37183053411 | `vehicles` | 2 | 2089 |
| 37183053411 | `vehicles` | 3 | 952 |
| 37183053411 | `workers` | 0 | 288 |
| 37183053411 | `workers` | 1 | 1784 |
| 37183053411 | `workers` | 2 | 1711 |
| 37183053411 | `workers` | 3 | 289 |

: Specification of a demographic scenario {#tbl-demographic-scenario}

While the format is conceptually simple, specifying scenarios this way is tedious. I do not have students do this; rather I create two scenarios in addition to the baseline that I include with the model. The "projected" scenario applies uniform growth factors derived from the cohort-component growth model we build in class several weeks, assuming future development will follow the spatial distribution that past development has. The "compact" scenario concentrates the same growth in the three major downtowns of the region—Raleigh, Durham, and Chapel Hill. For extra credit, I have students compare the results from the compact and projected scenarios; in a class where travel demand modeling was a larger part of the material, this comparison would be a core assignment.

# Estimation of a new model

Estimating a new model requires only a few lines of code, however it does require the 2017 National Household Travel Survey [NHTS, @NHTS_2017] and an OpenStreetMap PBF file for the region you wish to estimate the model for.^[OpenStreetMap PBF files for any region are easily obtained from [https://app.protomaps.com/](https://app.protomaps.com/).] The code to estimate a model for the Research Triangle region is below. First, it loads the relevant libraries, and then the NHTS. In this case, I filter the NHTS to only households in North Carolina with a weekday travel day ($n=7,146$). The final line estimates the model and stores the estimated model in the `result` variable. It requires the (possibly filtered) NHTS, the path to the OpenStreetMap data, the state and a vector of counties to define the region under study, and a year. Currently 2021 is most recent year available, as this is based on American Community Survey and Longitudinal Employer-Household Dynamics data availability.

Parsing the OpenStreetMap data uses Julia [@bezanson_julia_2017] for performance, which can be installed if it is not already by running `JuliaCall::install_julia()` from within R. Julia is only required for estimation; students do not need to install Julia.

```{r}
#| output: false
#| eval: false
library(MyFirstFourStepModel)
library(tidyverse)

# Load NHTS and filter to North Carolina weekday data
nhts = load_nhts(NHTS_PATH)
nhts$households = filter(
  nhts$households,
  HHSTATE == "NC" & TRAVDAY %in% c(2, 3, 4, 5, 6)
)

# Estimate the model using 2021 Census/LODES data for the Triangle
model = estimate(nhts, OSM_PATH, "NC", c("Durham", "Orange", "Wake"), 2021)
```

Creating land-use scenarios to include with the model is slightly more involved. The baseline can be saved as an Excel spreadsheet using the code:

```{r}
#| eval: false
save_landuse_scenario(model$scenarios$baseline, "baseline.xlsx")
```

The spreadsheet can then be edited, either manually or through custom code, to create the desired scenarios. Created scenarios can then be loaded back in with code like the following. This code assumes that the scenarios are in the `projected.xlsx` and `compact.xlsx` files, but there are no restrictions on the number of scenarios you may have or the names of them (other than that the names must be valid R variable names):

```{r}
#| eval: false
model$scenarios$projected = load_landuse_scenario("projected.xlsx")
model$scenarios$compact = load_landuse_scenario("compact.xlsx")
```

Lastly, the model can be saved to a file for distribution to students—in this case, in the file `rdu.model`. This can be loaded by the `load_model` function described above, either from a file or a URL. To use a scenario, students can replace `models$scenario$baseline` with `models$scenario$projected` or `models$scenario$compact` in the code presented above.

```{r}
#| eval: false
save_model(model, "rdu.model")
```

# Model architecture and input data

The sections above describe the user-facing interface for My First Four-Step Model. In this section, I turn to the technical details of the model architecture, estimation techniques, and data sources. For simplicity, TAZs in the model conform directly to Census tracts.

## Trip generation

Trip generation is based on the 2017 National Household Travel Survey. The model divides the day into four time periods: overnight (7:00 pm--5:59 am), AM Peak (6:00 am--9:59 am), midday (10:00 am--3:59 pm), and PM Peak (4:00 pm--6:59 pm). The model also divides trips into three purposes: home-based work (HBW), home-based other (HBO), and non-home-based (NHB). While this is fewer trip types and time periods than might be included in production travel models, it is consistent with the general practice of dividing trips by time of day and count. Trip generation can be estimated either for the full NHTS, or a subset more relevant to the region at hand. 

Household-level trip counts are estimated for each time period and trip type using a simple linear regression with the trip count as the dependent variable and independent variables for number of vehicles, household size, household income, Census tract residential density, and number of workers. This results in 12 regression equations, for each time period and trip purpose. Household income is represented by dummy variables for less than $35,000, $35,000–$74,999, $75,000–$99,999, and $100,000 or more.

These regression models are disaggregate, household-level models, whereas the four-step model is an aggregate model using marginal data at the tract level. Specifically, the model uses household size (topcoded at 4), number of workers (topcoded at 3), number of vehicles (topcoded at 3), and income (in the categories used in the regression). To apply the household-level model to this aggregate data, I disaggregate the data to household-level records (i.e. create a synthetic population) using iterative proportional fitting with a seed matrix derived from the Integrated Public Use Microdata Sample 2021 Five-Year American Community Survey data for the entire US [@ruggles_ipums_2024]. This seed matrix is precalculated and ships with the software. The regression equations are then used to predict household-level tripmaking, which is then re-aggregated to the tract level.

Trip attraction is somewhat more complicated, as the NHTS does not provide sufficient spatial detail to know where trips go. Instead, I use the Puget Sound Household Travel Survey, which includes origin and destination Census tract in the public-use dataset [@PSRC_Household_Travel_Survey]. I calculate the total number of home-based work and home-based other trips in each time period that have the non-home end in each Census tract in the Puget Sound region. I also calculate half the number of non-home-based trips in each time period that have either end in each tract (I divide by two to correctly reproduce the total number of non-home-based trips).

To extrapolate this data to tracts outside the region, I build linear regression models for each trip type and time period based on total employment and employment in retail, education, and accomodation/food services from the US Census Bureau Longitudinal Employer-Household Dynamics Origin-Destination Employment Statistics. For future-year scenarios, employment in each tract in each of these categories must be predicted, and supplied in a similar format to @tbl-demographic-scenario. Since the trip production model is likely to be more accurate, I balance total attractions by trip type in each time period to match estimated productions.

## Trip distribution

The trip distribution step uses a singly-constrained (at the production end) gravity model [@travelforecastingresource_destination_2020], of the form
$$
t_{ijpc} = P_{ipc} \frac{A_{jpc} d_{ij}^{\beta_c}}{\displaystyle\sum_{j'} A_{j'pc} d_{ij'}^{\beta_c}}
$$

where $t_{ijpc}$ is the total number of trips of type $c$ (home-based work, home-based other, or non-home-based) from TAZ $i$ to $j$ during time period $p$. $P_{ipc}$ is the total trips of type $c$ produced in TAZ $i$ during time period $p$, and $A_{jpc}$ is the total trips attracted to TAZ $j$. $\beta_c$ is the decay parameter for trip type $c$; the decay parameter is expected to be negative, and differs by trip type but not time period (though the spatial distribution of productions and attractions does vary by time period.) $d_{ij}$ is the crow-flies distance from the TAZ $i$ to TAZ $j$.

$\beta_c$ is calibrated for each trip type using the method introduced by Merlin [-@merlin_new_2020] based on the median trip length. The method observes that half of the weighted destinations should be closer to the origin than the median trip, and half should be further away. The parameter is calibrated using Brent's method to solve the problem^[This is slightly different than the function presented in Merlin [-@merlin_new_2020]. It divides by total weighted destinations to make the function have a single minimum; otherwise $\beta = -\infty$ is also a minimum as the total weighted destinations are zero. I replace the absolute value with squaring to make the derivative continuous at the optimal value.]
$$
\displaystyle\min_\beta \left(\frac{\displaystyle\sum_{i, j, d_{ij} < \tilde d} P_i A_j d_{ij}^\beta - \displaystyle\sum_{i, j, d_{ij} \geq \tilde d} P_i A_j d_{ij}^\beta}{\displaystyle\sum_{i, j} P_i A_j d_{ij}^\beta}\right)^2
$$
where $\tilde d$ is the median trip distance for the trip type under consideration (subscript $c$ suppressed for readability), and other variables are as defined previously.

The median trip distance is derived from the NHTS, or a subsample more relevant to the region being modeled. Since the NHTS reports network rather than crow-flies distance, I approximate the crow-flies distance for each NHTS trip by dividing the network distance by 1.3, a factor empirically determined by [@wang_how_2024].

For intrazonal trips, I assume a travel distance of $0.52 \sqrt{s}$, where $s$ is the area of the TAZ. This is based on a Monte Carlo simulation of the average distance between random points in a square. There are two opposing factors that bias this, which should somewhat cancel out. TAZ's are not square, and are less compact than a square, which increases average travel distance. However, development within a TAZ is also concentrated in certain areas, which decreases average travel distance.

## Mode choice

The mode choice model is a simple multinomial logit model estimated based on the NHTS. Because there is not detailed information about each trip and the alternatives available in the NHTS, the model is based solely on trip type, time period, travel distance, and housing unit density in the home tract. For non-home-based trips, a separate model is estimated excluding housing unit density. Goodness of fit is expected to be poor, but the point of the model is to demonstrate the simplest possible demand model, not to produce a highly accurate forecasting system. In theory it would be possible to include household characteristics, since trip productions are modeled using a disaggregate model. However, this would complicate the model system and defeat the purpose of building the simplest possible model for teaching purposes.

## Network assignment

The network assignment uses a Frank-Wolfe static traffic assignment algorithm [@ortuzar_modelling_2011]. First, I calculate hourly vehicle flows during each period using average vehicle occupancy for each period and trip type, and a hard coded "peaking factor" that accounts for the proportion of traffic during the time period that occurs in the busiest hour—for example, I assume 45% of the traffic in the three-hour PM Peak period occurs during the busiest hour. Then, I run the assignment algorithm, with impedances based on a Bureau of Public Roads-style function:
$$
t_{\mathrm{congested}} = \left(1 + 0.6 \left[\frac{f}{c}\right] ^ 5 \right) t_{\mathrm{freeflow}} 
$$

where $f$ is the predicted flow, $c$ is the link capacity, and $t_{\mathrm{congested}}$ and $t_\mathrm{freeflow}$ are congested and free-flow link travel times. The factors 0.6 and 5 are derived from the Southern California Association of Governments travel demand model [@southerncaliforniaassociationofgovernments_scag_2012].

The assignment algorithm is written in pure R. This is quite slow, but will run anywhere R does—an advantage when the model will be run on students' computers. For this reason, networks need to be simple, and regions small. In the example above, I use only the central three counties of the Research Triangle region. I derive the network from OpenStreetMap. By default, the estimation function retains only the most major roads—motorways, trunk, and primary roads (and associated ramps). Furthermore, I run the assignment algorithm only until the "relative gap"—a measure of the error in the estimate—is 1%, rather than the typically recommended 0.01% [@boyce_convergence_2004], to improve performance in the educational environment.

# Discussion and conclusion

This article introduced a new way of teaching travel demand modeling in introductory courses where most students will not go on to a career in demand modeling. The primary change is to move the step of working with an actual demand model _much_ earlier in the process, after only a few lectures. To facilitate this, I introduced the My First Four-Step Model R package, which implements a highly simplified demand model that can be run on students' machines and estimated anywhere in the US with only publicly-available data. With only a few lines of code, which I provide to students as a runnable R file, students can run a four-step model, and interact with and interpret the outputs. This gives them firsthand experience with a demand model, which will promote improved communications between model output consumers and model developers once the students enter the workforce.

I described my process and the assignment I give students for working with this model. I use the model in a general planning methods course, so the amount of course time spent on demand modeling is minimal. Logical extensions to the assignment would be to have students evaluate more land-use scenarios, as well as transportation network scenarios. The package currently does not support transportation network scenarios (other than by modifying the input), and specification of land-use scenarios is a tedious process. In future work, I hope to provide more intuitive tools for specifying and modifying scenarios.

Insufficient accounting for induced demand—the phenomenon of roadway expansion leading to additional demand [@downs_still_2004]—is a common criticism of four-step models. In my experience, it is a particular concern among planning students. My First Four-Step Model is worse even than most production travel models; it does not account for induced demand at all. While most models would use estimates of network travel time and travel cost in the distribution and mode choice, and thus be at least somewhat sensitive to changes in the network, My First Four-Step Model relies entirely on crow-flies distances. If the ability to specify network scenarios is added this must be addressed.

There are a number of tools that are widely used in standard travel demand modeling software that are not available in My First Four-Step Model. For instance, it is not possible to do screenline or select link analysis.

Equity is a topic at the top of mind for many students. While four-step models are generally not strong tools for evaluating equity, since they aggregate people of different demographic backgrounds early in the modeling process, there are some analyses that they can still support. For instance, one might evaluate whether traffic is likely to be heaviest in low-income or minority communities, or whether residents of these communities face longer-than-average travel times. The tools for this analysis are likewise not available.

My First Four-Step Model will never be appropriate for production travel demand modeling—that is not the purpose. It is also not appropriate as a sole teaching tool for students who will ultimately become modelers; they will need to be exposed to more complex theory and software in order to work in this space. However, it may be useful  as a first exercise even in courses that focus only on demand modeling, where students can have a chance to work with a simple model before diving into the more complex theories and software that are necessary for a detailed education in this area.

A key limitation of this research is that travel demand modeling was not covered in our introductory Planning Methods course at all prior to introducing the My First Four-Step Model package, so I was not able to evaluate how student learning outcomes changed. Though the exercises with the model were generally well received, I did not do any formal evaluation of student perspectives. Another avenue for future research is to formally evaluate how the hands-on modeling activity affects student learning outcomes.

# Acknowledgements

I wish to thank the students in Masters' of City and Regional Planning program, who inspire me to constantly improve my teaching methods.

Road network data in @fig-generation–@fig-congestion © OpenStreetMap contributors.

# References